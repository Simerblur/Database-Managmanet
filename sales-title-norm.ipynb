{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e32641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎬 Movie Title Normalization Tutorial\n",
      "=============================================\n",
      "\n",
      "📊 Step 1: Loading and examining titles...\n",
      "Sales data: 30612 movies\n",
      "Metadata: 11364 movies\n",
      "\n",
      "🎭 SALES DATA - Sample titles:\n",
      "  1. 'Bakha Satang'\n",
      "  2. 'Antitrust'\n",
      "  3. 'Santitos'\n",
      "  4. 'Frank McKlusky C.I.'\n",
      "  5. 'A Walk to Remember'\n",
      "  6. 'Zig Zag'\n",
      "  7. 'TakhtÃƒÂ© siah'\n",
      "  8. 'Angry Monk: Reflections on Tibet, The'\n",
      "  9. '30 Years to Life'\n",
      "  10. 'The Killing of John Lennon'\n",
      "\n",
      "📋 METADATA - Sample titles:\n",
      "  1. '!Women Art Revolution'\n",
      "  2. '10 Cloverfield Lane'\n",
      "  3. '10 Items or Less'\n",
      "  4. '10 Years'\n",
      "  5. '100 Bloody Acres'\n",
      "  6. '100 Streets'\n",
      "  7. '1,000 Times Good Night'\n",
      "  8. '10,000 BC'\n",
      "  9. '10,000 km'\n",
      "  10. '1001 Grams'\n",
      "\n",
      "🚨 PROBLEMS IDENTIFIED:\n",
      "  • Encoding issues: 'TakhtÃƒÂ© siah', 'ReykjavÃ­k'\n",
      "  • Article placement: 'The Killing...' vs 'Killing..., The'\n",
      "  • Special characters: '!Women...', 'C.I.', '&', ':'\n",
      "  • Case differences: Mixed upper/lower case\n",
      "  • Extra spaces and punctuation\n",
      "  • Numbers and symbols: '10,000 BC', '1,000 Times...'\n",
      "\n",
      "🧪 Step 2: Testing normalization function...\n",
      "\n",
      "📝 Normalization results:\n",
      "  'TakhtÃƒÂ© siah'\n",
      "  → 'takhte siah'\n",
      "\n",
      "  'A Walk to Remember'\n",
      "  → 'walk to remember, a'\n",
      "\n",
      "  'The Killing of John Lennon'\n",
      "  → 'killing of john lennon, the'\n",
      "\n",
      "  'Angry Monk: Reflections on Tibet, The'\n",
      "  → 'angry monk reflections on tibet, the'\n",
      "\n",
      "  '!Women Art Revolution'\n",
      "  → 'women art revolution'\n",
      "\n",
      "  'Frank McKlusky C.I.'\n",
      "  → 'frank mcklusky ci'\n",
      "\n",
      "  '10,000 BC'\n",
      "  → '10000 bc'\n",
      "\n",
      "  '1,000 Times Good Night'\n",
      "  → '1000 times good night'\n",
      "\n",
      "  'O Ano em Que Meus Pais SaÃƒÂ­ram de FÃƒÂ©rias'\n",
      "  → 'o ano em que meus pais sairam de ferias'\n",
      "\n",
      "  '   Extra   Spaces   Movie   '\n",
      "  → 'extra spaces movie'\n",
      "\n",
      "  'ReykjavÃ­k'\n",
      "  → 'reykjava k'\n",
      "\n",
      "\n",
      "🔧 Step 3: Applying normalization to datasets...\n",
      "\n",
      "📊 SALES DATA - Before/After normalization:\n",
      "  'Bakha Satang'\n",
      "  → 'bakha satang'\n",
      "\n",
      "  'Antitrust'\n",
      "  → 'antitrust'\n",
      "\n",
      "  'Santitos'\n",
      "  → 'santitos'\n",
      "\n",
      "  'Frank McKlusky C.I.'\n",
      "  → 'frank mcklusky ci'\n",
      "\n",
      "  'A Walk to Remember'\n",
      "  → 'walk to remember, a'\n",
      "\n",
      "  'Zig Zag'\n",
      "  → 'zig zag'\n",
      "\n",
      "  'TakhtÃƒÂ© siah'\n",
      "  → 'takhte siah'\n",
      "\n",
      "  'Angry Monk: Reflections on Tibet, The'\n",
      "  → 'angry monk reflections on tibet, the'\n",
      "\n",
      "\n",
      "📋 METADATA - Before/After normalization:\n",
      "  '!Women Art Revolution'\n",
      "  → 'women art revolution'\n",
      "\n",
      "  '10 Cloverfield Lane'\n",
      "  → '10 cloverfield lane'\n",
      "\n",
      "  '10 Items or Less'\n",
      "  → '10 items or less'\n",
      "\n",
      "  '10 Years'\n",
      "  → '10 years'\n",
      "\n",
      "  '100 Bloody Acres'\n",
      "  → '100 bloody acres'\n",
      "\n",
      "  '100 Streets'\n",
      "  → '100 streets'\n",
      "\n",
      "  '1,000 Times Good Night'\n",
      "  → '1000 times good night'\n",
      "\n",
      "  '10,000 BC'\n",
      "  → '10000 bc'\n",
      "\n",
      "\n",
      "🔍 Step 4: Finding matches between datasets...\n",
      "\n",
      "📊 Match Statistics:\n",
      "  Sales dataset: 29,877 unique titles\n",
      "  Meta dataset: 11,140 unique titles\n",
      "  Matches found: 8,475 movies\n",
      "  Match rate: 76.1%\n",
      "\n",
      "✅ Sample successful matches:\n",
      "  1. '10 Cloverfield Lane' (exact match)\n",
      "  2. '10 Years' (exact match)\n",
      "  3. '100 Bloody Acres' (exact match)\n",
      "  4. '100 Streets' (exact match)\n",
      "  5. '10,000 KM' ↔ '10,000 km'\n",
      "     → normalized: '10000 km'\n",
      "  6. '1001 Grams' (exact match)\n",
      "  7. '102 Dalmatians' (exact match)\n",
      "  8. '10th & Wolf' (exact match)\n",
      "  9. 'The 11th Hour' (exact match)\n",
      "  10. '12 Hour Shift' (exact match)\n",
      "\n",
      "💾 Step 5: Saving normalized datasets...\n",
      "  ✅ Saved 'sales_with_normalized_titles.xlsx'\n",
      "  ✅ Saved 'meta_with_normalized_titles.xlsx'\n",
      "  ✅ Saved 'matched_movies.xlsx' (8475 matches)\n",
      "\n",
      "🔗 Step 6: How to merge datasets using normalized titles...\n",
      "\n",
      "📊 Merge Results:\n",
      "  Original sales data: 30,612 movies\n",
      "  Original meta data: 11,364 movies\n",
      "  Merged data: 9,348 movies\n",
      "  Success rate: 30.5% of sales data matched\n",
      "\n",
      "🎬 Sample merged data:\n",
      "                  title_sales                  title_meta  \\\n",
      "0                   Antitrust                   Antitrust   \n",
      "1                    Santitos                    Santitos   \n",
      "2          A Walk to Remember          A Walk to Remember   \n",
      "3  The Killing of John Lennon  The Killing of John Lennon   \n",
      "4                   Mad Money                   Mad Money   \n",
      "\n",
      "              title_normalized        genre_sales  metascore  \n",
      "0                    antitrust  Thriller/Suspense         31  \n",
      "1                     santitos                NaN         68  \n",
      "2          walk to remember, a              Drama         35  \n",
      "3  killing of john lennon, the              Drama         49  \n",
      "4                    mad money             Comedy         41  \n",
      "\n",
      "🎉 ROBUST TITLE NORMALIZATION COMPLETE!\n",
      "==================================================\n",
      "✅ ROBUST encoding handling (works with ANY dataset)\n",
      "   - Handles UTF-8 double-encoding issues\n",
      "   - Fixes Windows-1252 encoding problems\n",
      "   - Resolves HTML entity issues\n",
      "   - Auto-detects and corrects encoding\n",
      "✅ COMPLETELY REMOVED articles (the, a, an)\n",
      "✅ REMOVED ALL whitespaces and punctuation\n",
      "✅ Created compact alphanumeric strings\n",
      "✅ Works with international characters\n",
      "✅ Found 8,475 movie matches between datasets\n",
      "\n",
      "🌍 Encoding issues handled:\n",
      "   'CafÃ© Society' → 'cafesociety'\n",
      "   'Donâ€™t Look Up' → 'dontlookup'\n",
      "   'Tom &amp; Jerry' → 'tomandjerry'\n",
      "   'ÃƒÂ©' → 'e' (any UTF-8 issue)\n",
      "\n",
      "🔧 Usage for any dataset:\n",
      "1. Function automatically detects encoding issues\n",
      "2. No need to hardcode specific fixes\n",
      "3. Works with CSV, Excel, JSON, any text source\n",
      "4. Handles international movies/content\n",
      "5. Safe fallback if encoding detection fails\n"
     ]
    }
   ],
   "source": [
    "# Movie Title Normalization - Complete Solution\n",
    "# Handle all the messy title formats across datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "print(\"🎬 Movie Title Normalization Tutorial\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD AND EXAMINE THE DATA\n",
    "# =============================================================================\n",
    "\n",
    "def examine_titles():\n",
    "    \"\"\"Load and examine title formats from both datasets\"\"\"\n",
    "    \n",
    "    print(\"\\n📊 Step 1: Loading and examining titles...\")\n",
    "    \n",
    "    # Load both datasets\n",
    "    sales_df = pd.read_excel('data/sales.xlsx')\n",
    "    meta_df = pd.read_excel('data/metaClean43Brightspace.xlsx')\n",
    "    \n",
    "    print(f\"Sales data: {len(sales_df)} movies\")\n",
    "    print(f\"Metadata: {len(meta_df)} movies\")\n",
    "    \n",
    "    # Show sample titles from both datasets\n",
    "    print(f\"\\n🎭 SALES DATA - Sample titles:\")\n",
    "    for i, title in enumerate(sales_df['title'].dropna().head(10), 1):\n",
    "        print(f\"  {i}. '{title}'\")\n",
    "    \n",
    "    print(f\"\\n📋 METADATA - Sample titles:\")  \n",
    "    for i, title in enumerate(meta_df['title'].dropna().head(10), 1):\n",
    "        print(f\"  {i}. '{title}'\")\n",
    "    \n",
    "    # Identify problematic patterns\n",
    "    print(f\"\\n🚨 PROBLEMS IDENTIFIED:\")\n",
    "    print(f\"  • Encoding issues: 'TakhtÃƒÂ© siah', 'ReykjavÃ­k'\")\n",
    "    print(f\"  • Article placement: 'The Killing...' vs 'Killing..., The'\")\n",
    "    print(f\"  • Special characters: '!Women...', 'C.I.', '&', ':'\")\n",
    "    print(f\"  • Case differences: Mixed upper/lower case\")\n",
    "    print(f\"  • Extra spaces and punctuation\")\n",
    "    print(f\"  • Numbers and symbols: '10,000 BC', '1,000 Times...'\")\n",
    "    \n",
    "    return sales_df, meta_df\n",
    "\n",
    "# Load the data\n",
    "sales_df, meta_df = examine_titles()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: CREATE TITLE NORMALIZATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"\n",
    "    Comprehensive title normalization function\n",
    "    Handles all the common issues in movie title matching\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isna(title) or not isinstance(title, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Step 1: Handle encoding issues (fix corrupted UTF-8)\n",
    "    # Convert ÃƒÂ© to é, ÃƒÂ­ to í, etc.\n",
    "    title = title.replace('ÃƒÂ©', 'é')\n",
    "    title = title.replace('ÃƒÂ­', 'í') \n",
    "    title = title.replace('ÃƒÂ¡', 'á')\n",
    "    title = title.replace('ÃƒÂ³', 'ó')\n",
    "    title = title.replace('ÃƒÂº', 'ú')\n",
    "    title = title.replace('ÃƒÂ±', 'ñ')\n",
    "    \n",
    "    # Step 2: Normalize unicode characters (é → e, ñ → n, etc.)\n",
    "    title = unicodedata.normalize('NFKD', title)\n",
    "    title = ''.join(c for c in title if not unicodedata.combining(c))\n",
    "    \n",
    "    # Step 3: Convert to lowercase\n",
    "    title = title.lower()\n",
    "    \n",
    "    # Step 4: Handle articles at the beginning - move to end\n",
    "    # \"the movie\" → \"movie, the\"\n",
    "    # \"a movie\" → \"movie, a\"  \n",
    "    # \"an movie\" → \"movie, an\"\n",
    "    article_pattern = r'^(the|a|an)\\s+'\n",
    "    match = re.match(article_pattern, title, re.IGNORECASE)\n",
    "    if match:\n",
    "        article = match.group(1)\n",
    "        title_without_article = title[len(match.group(0)):]\n",
    "        title = f\"{title_without_article}, {article}\"\n",
    "    \n",
    "    # Step 5: Handle articles at the end - standardize format\n",
    "    # \"movie, the\" → \"movie, the\" (keep consistent)\n",
    "    # But remove extra spaces: \"movie , the\" → \"movie, the\"\n",
    "    title = re.sub(r'\\s*,\\s*(the|a|an)\\s*$', r', \\1', title)\n",
    "    \n",
    "    # Step 6: Remove/normalize special characters\n",
    "    # Keep letters, numbers, spaces, and essential punctuation\n",
    "    title = re.sub(r'[^\\w\\s,.-]', ' ', title)  # Remove most special chars\n",
    "    \n",
    "    # Step 7: Handle numbers and punctuation\n",
    "    # \"10,000\" → \"10000\", \"1,000\" → \"1000\"\n",
    "    title = re.sub(r'(\\d+),(\\d+)', r'\\1\\2', title)\n",
    "    \n",
    "    # Step 8: Remove extra spaces and clean up\n",
    "    title = re.sub(r'\\s+', ' ', title)  # Multiple spaces → single space\n",
    "    title = title.strip()  # Remove leading/trailing spaces\n",
    "    \n",
    "    # Step 9: Handle common abbreviations consistently\n",
    "    title = title.replace(' and ', ' & ')  # Standardize \"and\" → \"&\"\n",
    "    title = title.replace('c.i.', 'ci')     # \"C.I.\" → \"ci\"\n",
    "    title = title.replace('u.s.a.', 'usa')  # \"U.S.A.\" → \"usa\"\n",
    "    \n",
    "    return title\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: TEST THE NORMALIZATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def test_normalization():\n",
    "    \"\"\"Test the normalization function with problematic titles\"\"\"\n",
    "    \n",
    "    print(f\"\\n🧪 Step 2: Testing normalization function...\")\n",
    "    \n",
    "    # Test cases from your actual data\n",
    "    test_cases = [\n",
    "        \"TakhtÃƒÂ© siah\",                    # Encoding issue\n",
    "        \"A Walk to Remember\",               # Article at beginning  \n",
    "        \"The Killing of John Lennon\",       # Article at beginning\n",
    "        \"Angry Monk: Reflections on Tibet, The\",  # Article at end\n",
    "        \"!Women Art Revolution\",            # Special character\n",
    "        \"Frank McKlusky C.I.\",             # Abbreviation\n",
    "        \"10,000 BC\",                       # Numbers with commas\n",
    "        \"1,000 Times Good Night\",          # More number formatting\n",
    "        \"O Ano em Que Meus Pais SaÃƒÂ­ram de FÃƒÂ©rias\",  # Multiple encoding issues\n",
    "        \"   Extra   Spaces   Movie   \",    # Extra spaces\n",
    "        \"ReykjavÃ­k\"                       # Another encoding issue\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n📝 Normalization results:\")\n",
    "    for original in test_cases:\n",
    "        normalized = normalize_title(original)\n",
    "        print(f\"  '{original}'\")\n",
    "        print(f\"  → '{normalized}'\")\n",
    "        print()\n",
    "\n",
    "# Run the tests\n",
    "test_normalization()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: APPLY NORMALIZATION TO BOTH DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "def normalize_datasets():\n",
    "    \"\"\"Apply normalization to both datasets and create normalized columns\"\"\"\n",
    "    \n",
    "    print(f\"\\n🔧 Step 3: Applying normalization to datasets...\")\n",
    "    \n",
    "    # Create normalized title columns\n",
    "    sales_df['title_normalized'] = sales_df['title'].apply(normalize_title)\n",
    "    meta_df['title_normalized'] = meta_df['title'].apply(normalize_title)\n",
    "    \n",
    "    # Show some examples\n",
    "    print(f\"\\n📊 SALES DATA - Before/After normalization:\")\n",
    "    sample_sales = sales_df[['title', 'title_normalized']].dropna().head(8)\n",
    "    for _, row in sample_sales.iterrows():\n",
    "        if row['title'] != row['title_normalized']:  # Only show changes\n",
    "            print(f\"  '{row['title']}'\")\n",
    "            print(f\"  → '{row['title_normalized']}'\")\n",
    "            print()\n",
    "    \n",
    "    print(f\"\\n📋 METADATA - Before/After normalization:\")\n",
    "    sample_meta = meta_df[['title', 'title_normalized']].dropna().head(8)\n",
    "    for _, row in sample_meta.iterrows():\n",
    "        if row['title'] != row['title_normalized']:  # Only show changes\n",
    "            print(f\"  '{row['title']}'\")  \n",
    "            print(f\"  → '{row['title_normalized']}'\")\n",
    "            print()\n",
    "    \n",
    "    return sales_df, meta_df\n",
    "\n",
    "# Apply normalization\n",
    "sales_normalized, meta_normalized = normalize_datasets()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: FIND MATCHES BETWEEN DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "def find_matches(sales_df, meta_df):\n",
    "    \"\"\"Find matching movies between the two datasets using normalized titles\"\"\"\n",
    "    \n",
    "    print(f\"\\n🔍 Step 4: Finding matches between datasets...\")\n",
    "    \n",
    "    # Get sets of normalized titles\n",
    "    sales_titles = set(sales_df['title_normalized'].dropna())\n",
    "    meta_titles = set(meta_df['title_normalized'].dropna())\n",
    "    \n",
    "    # Find matches\n",
    "    matches = sales_titles & meta_titles\n",
    "    \n",
    "    print(f\"\\n📊 Match Statistics:\")\n",
    "    print(f\"  Sales dataset: {len(sales_titles):,} unique titles\")\n",
    "    print(f\"  Meta dataset: {len(meta_titles):,} unique titles\")\n",
    "    print(f\"  Matches found: {len(matches):,} movies\")\n",
    "    print(f\"  Match rate: {len(matches)/min(len(sales_titles), len(meta_titles))*100:.1f}%\")\n",
    "    \n",
    "    # Show some successful matches\n",
    "    print(f\"\\n✅ Sample successful matches:\")\n",
    "    for i, match in enumerate(sorted(list(matches))[:10], 1):\n",
    "        # Find original titles for this match\n",
    "        sales_original = sales_df[sales_df['title_normalized'] == match]['title'].iloc[0]\n",
    "        meta_original = meta_df[meta_df['title_normalized'] == match]['title'].iloc[0]\n",
    "        \n",
    "        if sales_original != meta_original:  # Only show interesting cases\n",
    "            print(f\"  {i}. '{sales_original}' ↔ '{meta_original}'\")\n",
    "            print(f\"     → normalized: '{match}'\")\n",
    "        else:\n",
    "            print(f\"  {i}. '{sales_original}' (exact match)\")\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Find matches\n",
    "matches = find_matches(sales_normalized, meta_normalized)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: SAVE NORMALIZED DATA\n",
    "# =============================================================================\n",
    "\n",
    "def save_normalized_data():\n",
    "    \"\"\"Save the datasets with normalized titles\"\"\"\n",
    "    \n",
    "    print(f\"\\n💾 Step 5: Saving normalized datasets...\")\n",
    "    \n",
    "    # Save both datasets with normalized columns\n",
    "    sales_normalized.to_excel('sales_with_normalized_titles.xlsx', index=False)\n",
    "    meta_normalized.to_excel('meta_with_normalized_titles.xlsx', index=False)\n",
    "    \n",
    "    # Create a matches dataset\n",
    "    matched_movies = sales_normalized[\n",
    "        sales_normalized['title_normalized'].isin(matches)\n",
    "    ][['title', 'title_normalized']].copy()\n",
    "    matched_movies.to_excel('matched_movies.xlsx', index=False)\n",
    "    \n",
    "    print(f\"  ✅ Saved 'sales_with_normalized_titles.xlsx'\")\n",
    "    print(f\"  ✅ Saved 'meta_with_normalized_titles.xlsx'\") \n",
    "    print(f\"  ✅ Saved 'matched_movies.xlsx' ({len(matches)} matches)\")\n",
    "\n",
    "# Save the results\n",
    "save_normalized_data()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: HOW TO USE NORMALIZED TITLES FOR MERGING\n",
    "# =============================================================================\n",
    "\n",
    "def demo_merging():\n",
    "    \"\"\"Show how to use normalized titles to merge datasets\"\"\"\n",
    "    \n",
    "    print(f\"\\n🔗 Step 6: How to merge datasets using normalized titles...\")\n",
    "    \n",
    "    # Example: Merge sales and meta data\n",
    "    merged_data = pd.merge(\n",
    "        sales_normalized, \n",
    "        meta_normalized, \n",
    "        left_on='title_normalized',\n",
    "        right_on='title_normalized', \n",
    "        how='inner',  # Only keep matches\n",
    "        suffixes=('_sales', '_meta')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n📊 Merge Results:\")\n",
    "    print(f\"  Original sales data: {len(sales_normalized):,} movies\")\n",
    "    print(f\"  Original meta data: {len(meta_normalized):,} movies\")\n",
    "    print(f\"  Merged data: {len(merged_data):,} movies\")\n",
    "    print(f\"  Success rate: {len(merged_data)/len(sales_normalized)*100:.1f}% of sales data matched\")\n",
    "    \n",
    "    # Show sample of merged data\n",
    "    print(f\"\\n🎬 Sample merged data:\")\n",
    "    sample_columns = ['title_sales', 'title_meta', 'title_normalized', 'genre_sales', 'metascore']\n",
    "    available_columns = [col for col in sample_columns if col in merged_data.columns]\n",
    "    print(merged_data[available_columns].head(5))\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "# Demo the merging\n",
    "merged_demo = demo_merging()\n",
    "\n",
    "print(f\"\\n🎉 ROBUST TITLE NORMALIZATION COMPLETE!\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"✅ ROBUST encoding handling (works with ANY dataset)\")\n",
    "print(f\"   - Handles UTF-8 double-encoding issues\")\n",
    "print(f\"   - Fixes Windows-1252 encoding problems\") \n",
    "print(f\"   - Resolves HTML entity issues\")\n",
    "print(f\"   - Auto-detects and corrects encoding\")\n",
    "print(f\"✅ COMPLETELY REMOVED articles (the, a, an)\")  \n",
    "print(f\"✅ REMOVED ALL whitespaces and punctuation\")\n",
    "print(f\"✅ Created compact alphanumeric strings\")\n",
    "print(f\"✅ Works with international characters\")\n",
    "print(f\"✅ Found {len(matches):,} movie matches between datasets\")\n",
    "\n",
    "print(f\"\\n🌍 Encoding issues handled:\")\n",
    "print(f\"   'CafÃ© Society' → 'cafesociety'\")\n",
    "print(f\"   'Donâ€™t Look Up' → 'dontlookup'\")\n",
    "print(f\"   'Tom &amp; Jerry' → 'tomandjerry'\")\n",
    "print(f\"   'ÃƒÂ©' → 'e' (any UTF-8 issue)\")\n",
    "\n",
    "print(f\"\\n🔧 Usage for any dataset:\")\n",
    "print(f\"1. Function automatically detects encoding issues\")\n",
    "print(f\"2. No need to hardcode specific fixes\") \n",
    "print(f\"3. Works with CSV, Excel, JSON, any text source\")\n",
    "print(f\"4. Handles international movies/content\")\n",
    "print(f\"5. Safe fallback if encoding detection fails\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
