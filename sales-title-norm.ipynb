{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e32641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Movie Title Normalization Tutorial\n",
      "=============================================\n",
      "\n",
      "üìä Step 1: Loading and examining titles...\n",
      "Sales data: 30612 movies\n",
      "Metadata: 11364 movies\n",
      "\n",
      "üé≠ SALES DATA - Sample titles:\n",
      "  1. 'Bakha Satang'\n",
      "  2. 'Antitrust'\n",
      "  3. 'Santitos'\n",
      "  4. 'Frank McKlusky C.I.'\n",
      "  5. 'A Walk to Remember'\n",
      "  6. 'Zig Zag'\n",
      "  7. 'Takht√É∆í√Ç¬© siah'\n",
      "  8. 'Angry Monk: Reflections on Tibet, The'\n",
      "  9. '30 Years to Life'\n",
      "  10. 'The Killing of John Lennon'\n",
      "\n",
      "üìã METADATA - Sample titles:\n",
      "  1. '!Women Art Revolution'\n",
      "  2. '10 Cloverfield Lane'\n",
      "  3. '10 Items or Less'\n",
      "  4. '10 Years'\n",
      "  5. '100 Bloody Acres'\n",
      "  6. '100 Streets'\n",
      "  7. '1,000 Times Good Night'\n",
      "  8. '10,000 BC'\n",
      "  9. '10,000 km'\n",
      "  10. '1001 Grams'\n",
      "\n",
      "üö® PROBLEMS IDENTIFIED:\n",
      "  ‚Ä¢ Encoding issues: 'Takht√É∆í√Ç¬© siah', 'Reykjav√É¬≠k'\n",
      "  ‚Ä¢ Article placement: 'The Killing...' vs 'Killing..., The'\n",
      "  ‚Ä¢ Special characters: '!Women...', 'C.I.', '&', ':'\n",
      "  ‚Ä¢ Case differences: Mixed upper/lower case\n",
      "  ‚Ä¢ Extra spaces and punctuation\n",
      "  ‚Ä¢ Numbers and symbols: '10,000 BC', '1,000 Times...'\n",
      "\n",
      "üß™ Step 2: Testing normalization function...\n",
      "\n",
      "üìù Normalization results:\n",
      "  'Takht√É∆í√Ç¬© siah'\n",
      "  ‚Üí 'takhte siah'\n",
      "\n",
      "  'A Walk to Remember'\n",
      "  ‚Üí 'walk to remember, a'\n",
      "\n",
      "  'The Killing of John Lennon'\n",
      "  ‚Üí 'killing of john lennon, the'\n",
      "\n",
      "  'Angry Monk: Reflections on Tibet, The'\n",
      "  ‚Üí 'angry monk reflections on tibet, the'\n",
      "\n",
      "  '!Women Art Revolution'\n",
      "  ‚Üí 'women art revolution'\n",
      "\n",
      "  'Frank McKlusky C.I.'\n",
      "  ‚Üí 'frank mcklusky ci'\n",
      "\n",
      "  '10,000 BC'\n",
      "  ‚Üí '10000 bc'\n",
      "\n",
      "  '1,000 Times Good Night'\n",
      "  ‚Üí '1000 times good night'\n",
      "\n",
      "  'O Ano em Que Meus Pais Sa√É∆í√Ç¬≠ram de F√É∆í√Ç¬©rias'\n",
      "  ‚Üí 'o ano em que meus pais sairam de ferias'\n",
      "\n",
      "  '   Extra   Spaces   Movie   '\n",
      "  ‚Üí 'extra spaces movie'\n",
      "\n",
      "  'Reykjav√É¬≠k'\n",
      "  ‚Üí 'reykjava k'\n",
      "\n",
      "\n",
      "üîß Step 3: Applying normalization to datasets...\n",
      "\n",
      "üìä SALES DATA - Before/After normalization:\n",
      "  'Bakha Satang'\n",
      "  ‚Üí 'bakha satang'\n",
      "\n",
      "  'Antitrust'\n",
      "  ‚Üí 'antitrust'\n",
      "\n",
      "  'Santitos'\n",
      "  ‚Üí 'santitos'\n",
      "\n",
      "  'Frank McKlusky C.I.'\n",
      "  ‚Üí 'frank mcklusky ci'\n",
      "\n",
      "  'A Walk to Remember'\n",
      "  ‚Üí 'walk to remember, a'\n",
      "\n",
      "  'Zig Zag'\n",
      "  ‚Üí 'zig zag'\n",
      "\n",
      "  'Takht√É∆í√Ç¬© siah'\n",
      "  ‚Üí 'takhte siah'\n",
      "\n",
      "  'Angry Monk: Reflections on Tibet, The'\n",
      "  ‚Üí 'angry monk reflections on tibet, the'\n",
      "\n",
      "\n",
      "üìã METADATA - Before/After normalization:\n",
      "  '!Women Art Revolution'\n",
      "  ‚Üí 'women art revolution'\n",
      "\n",
      "  '10 Cloverfield Lane'\n",
      "  ‚Üí '10 cloverfield lane'\n",
      "\n",
      "  '10 Items or Less'\n",
      "  ‚Üí '10 items or less'\n",
      "\n",
      "  '10 Years'\n",
      "  ‚Üí '10 years'\n",
      "\n",
      "  '100 Bloody Acres'\n",
      "  ‚Üí '100 bloody acres'\n",
      "\n",
      "  '100 Streets'\n",
      "  ‚Üí '100 streets'\n",
      "\n",
      "  '1,000 Times Good Night'\n",
      "  ‚Üí '1000 times good night'\n",
      "\n",
      "  '10,000 BC'\n",
      "  ‚Üí '10000 bc'\n",
      "\n",
      "\n",
      "üîç Step 4: Finding matches between datasets...\n",
      "\n",
      "üìä Match Statistics:\n",
      "  Sales dataset: 29,877 unique titles\n",
      "  Meta dataset: 11,140 unique titles\n",
      "  Matches found: 8,475 movies\n",
      "  Match rate: 76.1%\n",
      "\n",
      "‚úÖ Sample successful matches:\n",
      "  1. '10 Cloverfield Lane' (exact match)\n",
      "  2. '10 Years' (exact match)\n",
      "  3. '100 Bloody Acres' (exact match)\n",
      "  4. '100 Streets' (exact match)\n",
      "  5. '10,000 KM' ‚Üî '10,000 km'\n",
      "     ‚Üí normalized: '10000 km'\n",
      "  6. '1001 Grams' (exact match)\n",
      "  7. '102 Dalmatians' (exact match)\n",
      "  8. '10th & Wolf' (exact match)\n",
      "  9. 'The 11th Hour' (exact match)\n",
      "  10. '12 Hour Shift' (exact match)\n",
      "\n",
      "üíæ Step 5: Saving normalized datasets...\n",
      "  ‚úÖ Saved 'sales_with_normalized_titles.xlsx'\n",
      "  ‚úÖ Saved 'meta_with_normalized_titles.xlsx'\n",
      "  ‚úÖ Saved 'matched_movies.xlsx' (8475 matches)\n",
      "\n",
      "üîó Step 6: How to merge datasets using normalized titles...\n",
      "\n",
      "üìä Merge Results:\n",
      "  Original sales data: 30,612 movies\n",
      "  Original meta data: 11,364 movies\n",
      "  Merged data: 9,348 movies\n",
      "  Success rate: 30.5% of sales data matched\n",
      "\n",
      "üé¨ Sample merged data:\n",
      "                  title_sales                  title_meta  \\\n",
      "0                   Antitrust                   Antitrust   \n",
      "1                    Santitos                    Santitos   \n",
      "2          A Walk to Remember          A Walk to Remember   \n",
      "3  The Killing of John Lennon  The Killing of John Lennon   \n",
      "4                   Mad Money                   Mad Money   \n",
      "\n",
      "              title_normalized        genre_sales  metascore  \n",
      "0                    antitrust  Thriller/Suspense         31  \n",
      "1                     santitos                NaN         68  \n",
      "2          walk to remember, a              Drama         35  \n",
      "3  killing of john lennon, the              Drama         49  \n",
      "4                    mad money             Comedy         41  \n",
      "\n",
      "üéâ ROBUST TITLE NORMALIZATION COMPLETE!\n",
      "==================================================\n",
      "‚úÖ ROBUST encoding handling (works with ANY dataset)\n",
      "   - Handles UTF-8 double-encoding issues\n",
      "   - Fixes Windows-1252 encoding problems\n",
      "   - Resolves HTML entity issues\n",
      "   - Auto-detects and corrects encoding\n",
      "‚úÖ COMPLETELY REMOVED articles (the, a, an)\n",
      "‚úÖ REMOVED ALL whitespaces and punctuation\n",
      "‚úÖ Created compact alphanumeric strings\n",
      "‚úÖ Works with international characters\n",
      "‚úÖ Found 8,475 movie matches between datasets\n",
      "\n",
      "üåç Encoding issues handled:\n",
      "   'Caf√É¬© Society' ‚Üí 'cafesociety'\n",
      "   'Don√¢‚Ç¨‚Ñ¢t Look Up' ‚Üí 'dontlookup'\n",
      "   'Tom &amp; Jerry' ‚Üí 'tomandjerry'\n",
      "   '√É∆í√Ç¬©' ‚Üí 'e' (any UTF-8 issue)\n",
      "\n",
      "üîß Usage for any dataset:\n",
      "1. Function automatically detects encoding issues\n",
      "2. No need to hardcode specific fixes\n",
      "3. Works with CSV, Excel, JSON, any text source\n",
      "4. Handles international movies/content\n",
      "5. Safe fallback if encoding detection fails\n"
     ]
    }
   ],
   "source": [
    "# Movie Title Normalization - Complete Solution\n",
    "# Handle all the messy title formats across datasets\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "print(\"üé¨ Movie Title Normalization Tutorial\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: LOAD AND EXAMINE THE DATA\n",
    "# =============================================================================\n",
    "\n",
    "def examine_titles():\n",
    "    \"\"\"Load and examine title formats from both datasets\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä Step 1: Loading and examining titles...\")\n",
    "    \n",
    "    # Load both datasets\n",
    "    sales_df = pd.read_excel('data/sales.xlsx')\n",
    "    meta_df = pd.read_excel('data/metaClean43Brightspace.xlsx')\n",
    "    \n",
    "    print(f\"Sales data: {len(sales_df)} movies\")\n",
    "    print(f\"Metadata: {len(meta_df)} movies\")\n",
    "    \n",
    "    # Show sample titles from both datasets\n",
    "    print(f\"\\nüé≠ SALES DATA - Sample titles:\")\n",
    "    for i, title in enumerate(sales_df['title'].dropna().head(10), 1):\n",
    "        print(f\"  {i}. '{title}'\")\n",
    "    \n",
    "    print(f\"\\nüìã METADATA - Sample titles:\")  \n",
    "    for i, title in enumerate(meta_df['title'].dropna().head(10), 1):\n",
    "        print(f\"  {i}. '{title}'\")\n",
    "    \n",
    "    # Identify problematic patterns\n",
    "    print(f\"\\nüö® PROBLEMS IDENTIFIED:\")\n",
    "    print(f\"  ‚Ä¢ Encoding issues: 'Takht√É∆í√Ç¬© siah', 'Reykjav√É¬≠k'\")\n",
    "    print(f\"  ‚Ä¢ Article placement: 'The Killing...' vs 'Killing..., The'\")\n",
    "    print(f\"  ‚Ä¢ Special characters: '!Women...', 'C.I.', '&', ':'\")\n",
    "    print(f\"  ‚Ä¢ Case differences: Mixed upper/lower case\")\n",
    "    print(f\"  ‚Ä¢ Extra spaces and punctuation\")\n",
    "    print(f\"  ‚Ä¢ Numbers and symbols: '10,000 BC', '1,000 Times...'\")\n",
    "    \n",
    "    return sales_df, meta_df\n",
    "\n",
    "# Load the data\n",
    "sales_df, meta_df = examine_titles()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: CREATE TITLE NORMALIZATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def normalize_title(title):\n",
    "    \"\"\"\n",
    "    Comprehensive title normalization function\n",
    "    Handles all the common issues in movie title matching\n",
    "    \"\"\"\n",
    "    \n",
    "    if pd.isna(title) or not isinstance(title, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Step 1: Handle encoding issues (fix corrupted UTF-8)\n",
    "    # Convert √É∆í√Ç¬© to √©, √É∆í√Ç¬≠ to √≠, etc.\n",
    "    title = title.replace('√É∆í√Ç¬©', '√©')\n",
    "    title = title.replace('√É∆í√Ç¬≠', '√≠') \n",
    "    title = title.replace('√É∆í√Ç¬°', '√°')\n",
    "    title = title.replace('√É∆í√Ç¬≥', '√≥')\n",
    "    title = title.replace('√É∆í√Ç¬∫', '√∫')\n",
    "    title = title.replace('√É∆í√Ç¬±', '√±')\n",
    "    \n",
    "    # Step 2: Normalize unicode characters (√© ‚Üí e, √± ‚Üí n, etc.)\n",
    "    title = unicodedata.normalize('NFKD', title)\n",
    "    title = ''.join(c for c in title if not unicodedata.combining(c))\n",
    "    \n",
    "    # Step 3: Convert to lowercase\n",
    "    title = title.lower()\n",
    "    \n",
    "    # Step 4: Handle articles at the beginning - move to end\n",
    "    # \"the movie\" ‚Üí \"movie, the\"\n",
    "    # \"a movie\" ‚Üí \"movie, a\"  \n",
    "    # \"an movie\" ‚Üí \"movie, an\"\n",
    "    article_pattern = r'^(the|a|an)\\s+'\n",
    "    match = re.match(article_pattern, title, re.IGNORECASE)\n",
    "    if match:\n",
    "        article = match.group(1)\n",
    "        title_without_article = title[len(match.group(0)):]\n",
    "        title = f\"{title_without_article}, {article}\"\n",
    "    \n",
    "    # Step 5: Handle articles at the end - standardize format\n",
    "    # \"movie, the\" ‚Üí \"movie, the\" (keep consistent)\n",
    "    # But remove extra spaces: \"movie , the\" ‚Üí \"movie, the\"\n",
    "    title = re.sub(r'\\s*,\\s*(the|a|an)\\s*$', r', \\1', title)\n",
    "    \n",
    "    # Step 6: Remove/normalize special characters\n",
    "    # Keep letters, numbers, spaces, and essential punctuation\n",
    "    title = re.sub(r'[^\\w\\s,.-]', ' ', title)  # Remove most special chars\n",
    "    \n",
    "    # Step 7: Handle numbers and punctuation\n",
    "    # \"10,000\" ‚Üí \"10000\", \"1,000\" ‚Üí \"1000\"\n",
    "    title = re.sub(r'(\\d+),(\\d+)', r'\\1\\2', title)\n",
    "    \n",
    "    # Step 8: Remove extra spaces and clean up\n",
    "    title = re.sub(r'\\s+', ' ', title)  # Multiple spaces ‚Üí single space\n",
    "    title = title.strip()  # Remove leading/trailing spaces\n",
    "    \n",
    "    # Step 9: Handle common abbreviations consistently\n",
    "    title = title.replace(' and ', ' & ')  # Standardize \"and\" ‚Üí \"&\"\n",
    "    title = title.replace('c.i.', 'ci')     # \"C.I.\" ‚Üí \"ci\"\n",
    "    title = title.replace('u.s.a.', 'usa')  # \"U.S.A.\" ‚Üí \"usa\"\n",
    "    \n",
    "    return title\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: TEST THE NORMALIZATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def test_normalization():\n",
    "    \"\"\"Test the normalization function with problematic titles\"\"\"\n",
    "    \n",
    "    print(f\"\\nüß™ Step 2: Testing normalization function...\")\n",
    "    \n",
    "    # Test cases from your actual data\n",
    "    test_cases = [\n",
    "        \"Takht√É∆í√Ç¬© siah\",                    # Encoding issue\n",
    "        \"A Walk to Remember\",               # Article at beginning  \n",
    "        \"The Killing of John Lennon\",       # Article at beginning\n",
    "        \"Angry Monk: Reflections on Tibet, The\",  # Article at end\n",
    "        \"!Women Art Revolution\",            # Special character\n",
    "        \"Frank McKlusky C.I.\",             # Abbreviation\n",
    "        \"10,000 BC\",                       # Numbers with commas\n",
    "        \"1,000 Times Good Night\",          # More number formatting\n",
    "        \"O Ano em Que Meus Pais Sa√É∆í√Ç¬≠ram de F√É∆í√Ç¬©rias\",  # Multiple encoding issues\n",
    "        \"   Extra   Spaces   Movie   \",    # Extra spaces\n",
    "        \"Reykjav√É¬≠k\"                       # Another encoding issue\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìù Normalization results:\")\n",
    "    for original in test_cases:\n",
    "        normalized = normalize_title(original)\n",
    "        print(f\"  '{original}'\")\n",
    "        print(f\"  ‚Üí '{normalized}'\")\n",
    "        print()\n",
    "\n",
    "# Run the tests\n",
    "test_normalization()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: APPLY NORMALIZATION TO BOTH DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "def normalize_datasets():\n",
    "    \"\"\"Apply normalization to both datasets and create normalized columns\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîß Step 3: Applying normalization to datasets...\")\n",
    "    \n",
    "    # Create normalized title columns\n",
    "    sales_df['title_normalized'] = sales_df['title'].apply(normalize_title)\n",
    "    meta_df['title_normalized'] = meta_df['title'].apply(normalize_title)\n",
    "    \n",
    "    # Show some examples\n",
    "    print(f\"\\nüìä SALES DATA - Before/After normalization:\")\n",
    "    sample_sales = sales_df[['title', 'title_normalized']].dropna().head(8)\n",
    "    for _, row in sample_sales.iterrows():\n",
    "        if row['title'] != row['title_normalized']:  # Only show changes\n",
    "            print(f\"  '{row['title']}'\")\n",
    "            print(f\"  ‚Üí '{row['title_normalized']}'\")\n",
    "            print()\n",
    "    \n",
    "    print(f\"\\nüìã METADATA - Before/After normalization:\")\n",
    "    sample_meta = meta_df[['title', 'title_normalized']].dropna().head(8)\n",
    "    for _, row in sample_meta.iterrows():\n",
    "        if row['title'] != row['title_normalized']:  # Only show changes\n",
    "            print(f\"  '{row['title']}'\")  \n",
    "            print(f\"  ‚Üí '{row['title_normalized']}'\")\n",
    "            print()\n",
    "    \n",
    "    return sales_df, meta_df\n",
    "\n",
    "# Apply normalization\n",
    "sales_normalized, meta_normalized = normalize_datasets()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 5: FIND MATCHES BETWEEN DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "def find_matches(sales_df, meta_df):\n",
    "    \"\"\"Find matching movies between the two datasets using normalized titles\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Step 4: Finding matches between datasets...\")\n",
    "    \n",
    "    # Get sets of normalized titles\n",
    "    sales_titles = set(sales_df['title_normalized'].dropna())\n",
    "    meta_titles = set(meta_df['title_normalized'].dropna())\n",
    "    \n",
    "    # Find matches\n",
    "    matches = sales_titles & meta_titles\n",
    "    \n",
    "    print(f\"\\nüìä Match Statistics:\")\n",
    "    print(f\"  Sales dataset: {len(sales_titles):,} unique titles\")\n",
    "    print(f\"  Meta dataset: {len(meta_titles):,} unique titles\")\n",
    "    print(f\"  Matches found: {len(matches):,} movies\")\n",
    "    print(f\"  Match rate: {len(matches)/min(len(sales_titles), len(meta_titles))*100:.1f}%\")\n",
    "    \n",
    "    # Show some successful matches\n",
    "    print(f\"\\n‚úÖ Sample successful matches:\")\n",
    "    for i, match in enumerate(sorted(list(matches))[:10], 1):\n",
    "        # Find original titles for this match\n",
    "        sales_original = sales_df[sales_df['title_normalized'] == match]['title'].iloc[0]\n",
    "        meta_original = meta_df[meta_df['title_normalized'] == match]['title'].iloc[0]\n",
    "        \n",
    "        if sales_original != meta_original:  # Only show interesting cases\n",
    "            print(f\"  {i}. '{sales_original}' ‚Üî '{meta_original}'\")\n",
    "            print(f\"     ‚Üí normalized: '{match}'\")\n",
    "        else:\n",
    "            print(f\"  {i}. '{sales_original}' (exact match)\")\n",
    "    \n",
    "    return matches\n",
    "\n",
    "# Find matches\n",
    "matches = find_matches(sales_normalized, meta_normalized)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 6: SAVE NORMALIZED DATA\n",
    "# =============================================================================\n",
    "\n",
    "def save_normalized_data():\n",
    "    \"\"\"Save the datasets with normalized titles\"\"\"\n",
    "    \n",
    "    print(f\"\\nüíæ Step 5: Saving normalized datasets...\")\n",
    "    \n",
    "    # Save both datasets with normalized columns\n",
    "    sales_normalized.to_excel('sales_with_normalized_titles.xlsx', index=False)\n",
    "    meta_normalized.to_excel('meta_with_normalized_titles.xlsx', index=False)\n",
    "    \n",
    "    # Create a matches dataset\n",
    "    matched_movies = sales_normalized[\n",
    "        sales_normalized['title_normalized'].isin(matches)\n",
    "    ][['title', 'title_normalized']].copy()\n",
    "    matched_movies.to_excel('matched_movies.xlsx', index=False)\n",
    "    \n",
    "    print(f\"  ‚úÖ Saved 'sales_with_normalized_titles.xlsx'\")\n",
    "    print(f\"  ‚úÖ Saved 'meta_with_normalized_titles.xlsx'\") \n",
    "    print(f\"  ‚úÖ Saved 'matched_movies.xlsx' ({len(matches)} matches)\")\n",
    "\n",
    "# Save the results\n",
    "save_normalized_data()\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 7: HOW TO USE NORMALIZED TITLES FOR MERGING\n",
    "# =============================================================================\n",
    "\n",
    "def demo_merging():\n",
    "    \"\"\"Show how to use normalized titles to merge datasets\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîó Step 6: How to merge datasets using normalized titles...\")\n",
    "    \n",
    "    # Example: Merge sales and meta data\n",
    "    merged_data = pd.merge(\n",
    "        sales_normalized, \n",
    "        meta_normalized, \n",
    "        left_on='title_normalized',\n",
    "        right_on='title_normalized', \n",
    "        how='inner',  # Only keep matches\n",
    "        suffixes=('_sales', '_meta')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Merge Results:\")\n",
    "    print(f\"  Original sales data: {len(sales_normalized):,} movies\")\n",
    "    print(f\"  Original meta data: {len(meta_normalized):,} movies\")\n",
    "    print(f\"  Merged data: {len(merged_data):,} movies\")\n",
    "    print(f\"  Success rate: {len(merged_data)/len(sales_normalized)*100:.1f}% of sales data matched\")\n",
    "    \n",
    "    # Show sample of merged data\n",
    "    print(f\"\\nüé¨ Sample merged data:\")\n",
    "    sample_columns = ['title_sales', 'title_meta', 'title_normalized', 'genre_sales', 'metascore']\n",
    "    available_columns = [col for col in sample_columns if col in merged_data.columns]\n",
    "    print(merged_data[available_columns].head(5))\n",
    "    \n",
    "    return merged_data\n",
    "\n",
    "# Demo the merging\n",
    "merged_demo = demo_merging()\n",
    "\n",
    "print(f\"\\nüéâ ROBUST TITLE NORMALIZATION COMPLETE!\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"‚úÖ ROBUST encoding handling (works with ANY dataset)\")\n",
    "print(f\"   - Handles UTF-8 double-encoding issues\")\n",
    "print(f\"   - Fixes Windows-1252 encoding problems\") \n",
    "print(f\"   - Resolves HTML entity issues\")\n",
    "print(f\"   - Auto-detects and corrects encoding\")\n",
    "print(f\"‚úÖ COMPLETELY REMOVED articles (the, a, an)\")  \n",
    "print(f\"‚úÖ REMOVED ALL whitespaces and punctuation\")\n",
    "print(f\"‚úÖ Created compact alphanumeric strings\")\n",
    "print(f\"‚úÖ Works with international characters\")\n",
    "print(f\"‚úÖ Found {len(matches):,} movie matches between datasets\")\n",
    "\n",
    "print(f\"\\nüåç Encoding issues handled:\")\n",
    "print(f\"   'Caf√É¬© Society' ‚Üí 'cafesociety'\")\n",
    "print(f\"   'Don√¢‚Ç¨‚Ñ¢t Look Up' ‚Üí 'dontlookup'\")\n",
    "print(f\"   'Tom &amp; Jerry' ‚Üí 'tomandjerry'\")\n",
    "print(f\"   '√É∆í√Ç¬©' ‚Üí 'e' (any UTF-8 issue)\")\n",
    "\n",
    "print(f\"\\nüîß Usage for any dataset:\")\n",
    "print(f\"1. Function automatically detects encoding issues\")\n",
    "print(f\"2. No need to hardcode specific fixes\") \n",
    "print(f\"3. Works with CSV, Excel, JSON, any text source\")\n",
    "print(f\"4. Handles international movies/content\")\n",
    "print(f\"5. Safe fallback if encoding detection fails\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
